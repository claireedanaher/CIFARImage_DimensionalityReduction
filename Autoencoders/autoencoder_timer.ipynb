{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On CIFAR10 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kpvedula\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Data Loading and Preprocessing\n",
    "from IPython.display import Image, SVG\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST data set and scale the images to a range between 0 and 1\n",
    "\n",
    "# Load the training and test data sets\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Scales the training and test data to range between 0 and 1.\n",
    "max_value = float(x_train.max())\n",
    "x_train = x_train.astype('float32') / max_value\n",
    "x_test = x_test.astype('float32') / max_value\n",
    "\n",
    "# The data set consists 3D arrays with 60K training and 10K test images with a resolution of 28 x 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the 3D arrays as matrices. In doing so, we'll reshape the 28 x 28 images into vectors of length 784\n",
    "\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "print(x_train[:100].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression factor: 1024.0\n"
     ]
    }
   ],
   "source": [
    "# input dimension = 784\n",
    "\n",
    "input_dim = x_train.shape[1]\n",
    "encoding_dim = 3\n",
    "\n",
    "compression_factor = float(input_dim) / encoding_dim\n",
    "print(\"Compression factor: %s\" % compression_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_autoencoder_CIFAR(x_train, x_test):\n",
    "#     autoencoder = Sequential()\n",
    "#     autoencoder.add(\n",
    "#         Dense(encoding_dim, input_shape=(input_dim,), activation='relu')\n",
    "#     )\n",
    "#     autoencoder.add(\n",
    "#         Dense(input_dim, activation='sigmoid')\n",
    "#     )\n",
    "\n",
    "#     autoencoder.summary()\n",
    "#     input_img = Input(shape=(input_dim,))\n",
    "#     encoder_layer = autoencoder.layers[0]\n",
    "#     encoder = Model(input_img, encoder_layer(input_img))\n",
    "\n",
    "#     encoder.summary()\n",
    "#     autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "#     autoencoder.fit(x_train, x_train,\n",
    "#                     epochs=50,\n",
    "#                     batch_size=256,\n",
    "#                     shuffle=True,\n",
    "#                     validation_data=(x_test, x_test))\n",
    "    \n",
    "    autoencoder = Sequential()\n",
    "\n",
    "    # Encoder Layers\n",
    "    autoencoder.add(Dense(4 * encoding_dim, input_shape=(input_dim,), activation='relu'))\n",
    "    autoencoder.add(Dense(2 * encoding_dim, activation='relu'))\n",
    "    autoencoder.add(Dense(encoding_dim, activation='relu'))\n",
    "\n",
    "    # Decoder Layers\n",
    "    autoencoder.add(Dense(2 * encoding_dim, activation='relu'))\n",
    "    autoencoder.add(Dense(4 * encoding_dim, activation='relu'))\n",
    "    autoencoder.add(Dense(input_dim, activation='sigmoid'))\n",
    "\n",
    "    autoencoder.summary()\n",
    "\n",
    "    input_img = Input(shape=(input_dim,))\n",
    "    encoder_layer1 = autoencoder.layers[0]\n",
    "    encoder_layer2 = autoencoder.layers[1]\n",
    "    encoder_layer3 = autoencoder.layers[2]\n",
    "    encoder = Model(input_img, encoder_layer3(encoder_layer2(encoder_layer1(input_img))))\n",
    "\n",
    "    encoder.summary()\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    autoencoder.fit(x_train, x_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                36876     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3072)              39936     \n",
      "=================================================================\n",
      "Total params: 77,019\n",
      "Trainable params: 77,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                36876     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 36,975\n",
      "Trainable params: 36,975\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 100 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.6932 - val_loss: 0.6931\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6931 - val_loss: 0.6931\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6930 - val_loss: 0.6930\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6929 - val_loss: 0.6930\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6928 - val_loss: 0.6929\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6928 - val_loss: 0.6929\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6927 - val_loss: 0.6928\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6926 - val_loss: 0.6928\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6924 - val_loss: 0.6927\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6923 - val_loss: 0.6927\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6922 - val_loss: 0.6926\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6920 - val_loss: 0.6925\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6918 - val_loss: 0.6924\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6916 - val_loss: 0.6924\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6915 - val_loss: 0.6923\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6913 - val_loss: 0.6922\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6910 - val_loss: 0.6922\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6908 - val_loss: 0.6921\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6906 - val_loss: 0.6921\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6904 - val_loss: 0.6921\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6902 - val_loss: 0.6920\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6899 - val_loss: 0.6920\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6897 - val_loss: 0.6920\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6895 - val_loss: 0.6919\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6892 - val_loss: 0.6919\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6890 - val_loss: 0.6919\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6888 - val_loss: 0.6918\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6886 - val_loss: 0.6917\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6883 - val_loss: 0.6916\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6881 - val_loss: 0.6915\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6879 - val_loss: 0.6914\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6877 - val_loss: 0.6913\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6875 - val_loss: 0.6912\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6873 - val_loss: 0.6910\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6871 - val_loss: 0.6909\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6869 - val_loss: 0.6908\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6868 - val_loss: 0.6906\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6866 - val_loss: 0.6905\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6864 - val_loss: 0.6903\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6862 - val_loss: 0.6902\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6861 - val_loss: 0.6900\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6859 - val_loss: 0.6898\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6857 - val_loss: 0.6896\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6856 - val_loss: 0.6894\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6854 - val_loss: 0.6892\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6852 - val_loss: 0.6890\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6850 - val_loss: 0.6887\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6848 - val_loss: 0.6885\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6846 - val_loss: 0.6882\n",
      "embedding created\n",
      "--- 100 records ---\n",
      "--- 15.190400123596191 seconds ---\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 12)                36876     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3072)              39936     \n",
      "=================================================================\n",
      "Total params: 77,019\n",
      "Trainable params: 77,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 12)                36876     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 36,975\n",
      "Trainable params: 36,975\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 1s 906us/step - loss: 0.6931 - val_loss: 0.6930\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 0s 354us/step - loss: 0.6930 - val_loss: 0.6929\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 0s 301us/step - loss: 0.6928 - val_loss: 0.6928\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 0s 318us/step - loss: 0.6927 - val_loss: 0.6927\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 0s 302us/step - loss: 0.6926 - val_loss: 0.6926\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 0s 299us/step - loss: 0.6924 - val_loss: 0.6924\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 0s 299us/step - loss: 0.6923 - val_loss: 0.6923\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 0s 307us/step - loss: 0.6921 - val_loss: 0.6922\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 0s 304us/step - loss: 0.6920 - val_loss: 0.6921\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 0s 304us/step - loss: 0.6918 - val_loss: 0.6919\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 0s 301us/step - loss: 0.6917 - val_loss: 0.6918\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 0s 304us/step - loss: 0.6915 - val_loss: 0.6917\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 0s 304us/step - loss: 0.6913 - val_loss: 0.6915\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 0s 300us/step - loss: 0.6912 - val_loss: 0.6914\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 0s 308us/step - loss: 0.6910 - val_loss: 0.6912\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 0s 302us/step - loss: 0.6908 - val_loss: 0.6911\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 0s 300us/step - loss: 0.6906 - val_loss: 0.6909\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 0s 299us/step - loss: 0.6904 - val_loss: 0.6908\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 0s 303us/step - loss: 0.6903 - val_loss: 0.6906\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 0s 304us/step - loss: 0.6901 - val_loss: 0.6905\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 0s 301us/step - loss: 0.6899 - val_loss: 0.6904\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 0s 300us/step - loss: 0.6897 - val_loss: 0.6903\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 0s 308us/step - loss: 0.6896 - val_loss: 0.6901\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 0s 299us/step - loss: 0.6894 - val_loss: 0.6900\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 0s 299us/step - loss: 0.6893 - val_loss: 0.6900\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 0s 302us/step - loss: 0.6892 - val_loss: 0.6899\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 0s 302us/step - loss: 0.6890 - val_loss: 0.6898\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 0s 300us/step - loss: 0.6889 - val_loss: 0.6897\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 0s 302us/step - loss: 0.6888 - val_loss: 0.6897\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 0s 298us/step - loss: 0.6888 - val_loss: 0.6897\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 0s 298us/step - loss: 0.6887 - val_loss: 0.6896\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 0s 298us/step - loss: 0.6886 - val_loss: 0.6896\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 0s 299us/step - loss: 0.6886 - val_loss: 0.6896\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 0s 300us/step - loss: 0.6885 - val_loss: 0.6896\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 0s 300us/step - loss: 0.6885 - val_loss: 0.6895\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 0s 306us/step - loss: 0.6885 - val_loss: 0.6895\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 0s 310us/step - loss: 0.6884 - val_loss: 0.6895\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 0s 302us/step - loss: 0.6884 - val_loss: 0.6895\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 0s 301us/step - loss: 0.6884 - val_loss: 0.6895\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 0s 299us/step - loss: 0.6884 - val_loss: 0.6895\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 0s 304us/step - loss: 0.6884 - val_loss: 0.6895\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 0s 303us/step - loss: 0.6884 - val_loss: 0.6895\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 0s 300us/step - loss: 0.6884 - val_loss: 0.6895\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 0s 296us/step - loss: 0.6883 - val_loss: 0.6895\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 0s 296us/step - loss: 0.6883 - val_loss: 0.6895\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 0s 315us/step - loss: 0.6883 - val_loss: 0.6895\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 0s 297us/step - loss: 0.6883 - val_loss: 0.6895\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 0s 299us/step - loss: 0.6883 - val_loss: 0.6895\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 0s 301us/step - loss: 0.6883 - val_loss: 0.6895\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 0s 300us/step - loss: 0.6883 - val_loss: 0.6895\n",
      "embedding created\n",
      "--- 1000 records ---\n",
      "--- 16.479872465133667 seconds ---\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 12)                36876     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3072)              39936     \n",
      "=================================================================\n",
      "Total params: 77,019\n",
      "Trainable params: 77,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 12)                36876     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 36,975\n",
      "Trainable params: 36,975\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "5000/5000 [==============================] - 1s 228us/step - loss: 0.6916 - val_loss: 0.6879\n",
      "Epoch 2/50\n",
      "5000/5000 [==============================] - 0s 96us/step - loss: 0.6827 - val_loss: 0.6787\n",
      "Epoch 3/50\n",
      "5000/5000 [==============================] - 0s 97us/step - loss: 0.6765 - val_loss: 0.6762\n",
      "Epoch 4/50\n",
      "5000/5000 [==============================] - 1s 104us/step - loss: 0.6743 - val_loss: 0.6739\n",
      "Epoch 5/50\n",
      "5000/5000 [==============================] - 1s 106us/step - loss: 0.6717 - val_loss: 0.6713\n",
      "Epoch 6/50\n",
      "5000/5000 [==============================] - 0s 97us/step - loss: 0.6677 - val_loss: 0.6659\n",
      "Epoch 7/50\n",
      "5000/5000 [==============================] - 0s 97us/step - loss: 0.6614 - val_loss: 0.6585\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 98us/step - loss: 0.6559 - val_loss: 0.6547\n",
      "Epoch 9/50\n",
      "5000/5000 [==============================] - 0s 96us/step - loss: 0.6526 - val_loss: 0.6521\n",
      "Epoch 10/50\n",
      "5000/5000 [==============================] - 0s 97us/step - loss: 0.6503 - val_loss: 0.6502\n",
      "Epoch 11/50\n",
      "5000/5000 [==============================] - 1s 105us/step - loss: 0.6480 - val_loss: 0.6487\n",
      "Epoch 12/50\n",
      "5000/5000 [==============================] - 1s 101us/step - loss: 0.6464 - val_loss: 0.6464\n",
      "Epoch 13/50\n",
      "5000/5000 [==============================] - 1s 110us/step - loss: 0.6450 - val_loss: 0.6451\n",
      "Epoch 14/50\n",
      "5000/5000 [==============================] - 0s 96us/step - loss: 0.6435 - val_loss: 0.6441\n",
      "Epoch 15/50\n",
      "5000/5000 [==============================] - 0s 96us/step - loss: 0.6424 - val_loss: 0.6431\n",
      "Epoch 16/50\n",
      "5000/5000 [==============================] - 0s 96us/step - loss: 0.6415 - val_loss: 0.6423\n",
      "Epoch 17/50\n",
      "5000/5000 [==============================] - 0s 98us/step - loss: 0.6404 - val_loss: 0.6415\n",
      "Epoch 18/50\n",
      "5000/5000 [==============================] - 1s 103us/step - loss: 0.6397 - val_loss: 0.6409\n",
      "Epoch 19/50\n",
      "5000/5000 [==============================] - 1s 113us/step - loss: 0.6390 - val_loss: 0.6407\n",
      "Epoch 20/50\n",
      "5000/5000 [==============================] - 1s 109us/step - loss: 0.6385 - val_loss: 0.6398\n",
      "Epoch 21/50\n",
      "5000/5000 [==============================] - 1s 104us/step - loss: 0.6380 - val_loss: 0.6402\n",
      "Epoch 22/50\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.6378 - val_loss: 0.6390\n",
      "Epoch 23/50\n",
      "5000/5000 [==============================] - 0s 98us/step - loss: 0.6372 - val_loss: 0.6387\n",
      "Epoch 24/50\n",
      "5000/5000 [==============================] - 1s 103us/step - loss: 0.6367 - val_loss: 0.6384\n",
      "Epoch 25/50\n",
      "5000/5000 [==============================] - 1s 102us/step - loss: 0.6364 - val_loss: 0.6380\n",
      "Epoch 26/50\n",
      "5000/5000 [==============================] - 1s 102us/step - loss: 0.6362 - val_loss: 0.6378\n",
      "Epoch 27/50\n",
      "5000/5000 [==============================] - 1s 105us/step - loss: 0.6359 - val_loss: 0.6375\n",
      "Epoch 28/50\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.6359 - val_loss: 0.6375\n",
      "Epoch 29/50\n",
      "5000/5000 [==============================] - 0s 99us/step - loss: 0.6356 - val_loss: 0.6373\n",
      "Epoch 30/50\n",
      "5000/5000 [==============================] - 1s 102us/step - loss: 0.6355 - val_loss: 0.6372\n",
      "Epoch 31/50\n",
      "5000/5000 [==============================] - 0s 99us/step - loss: 0.6354 - val_loss: 0.6372\n",
      "Epoch 32/50\n",
      "5000/5000 [==============================] - 0s 99us/step - loss: 0.6354 - val_loss: 0.6372\n",
      "Epoch 33/50\n",
      "5000/5000 [==============================] - 0s 100us/step - loss: 0.6352 - val_loss: 0.6370\n",
      "Epoch 34/50\n",
      "5000/5000 [==============================] - 1s 101us/step - loss: 0.6351 - val_loss: 0.6369\n",
      "Epoch 35/50\n",
      "5000/5000 [==============================] - 0s 98us/step - loss: 0.6352 - val_loss: 0.6370\n",
      "Epoch 36/50\n",
      "5000/5000 [==============================] - 1s 105us/step - loss: 0.6350 - val_loss: 0.6367\n",
      "Epoch 37/50\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.6350 - val_loss: 0.6367\n",
      "Epoch 38/50\n",
      "5000/5000 [==============================] - 1s 104us/step - loss: 0.6350 - val_loss: 0.6367\n",
      "Epoch 39/50\n",
      "5000/5000 [==============================] - 1s 101us/step - loss: 0.6349 - val_loss: 0.6367\n",
      "Epoch 40/50\n",
      "5000/5000 [==============================] - 1s 104us/step - loss: 0.6349 - val_loss: 0.6368\n",
      "Epoch 41/50\n",
      "5000/5000 [==============================] - 1s 105us/step - loss: 0.6349 - val_loss: 0.6367\n",
      "Epoch 42/50\n",
      "5000/5000 [==============================] - 1s 104us/step - loss: 0.6350 - val_loss: 0.6366\n",
      "Epoch 43/50\n",
      "5000/5000 [==============================] - 0s 99us/step - loss: 0.6350 - val_loss: 0.6367\n",
      "Epoch 44/50\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.6349 - val_loss: 0.6367\n",
      "Epoch 45/50\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.6348 - val_loss: 0.6365\n",
      "Epoch 46/50\n",
      "5000/5000 [==============================] - 0s 98us/step - loss: 0.6348 - val_loss: 0.6368\n",
      "Epoch 47/50\n",
      "5000/5000 [==============================] - 1s 102us/step - loss: 0.6349 - val_loss: 0.6367\n",
      "Epoch 48/50\n",
      "5000/5000 [==============================] - 0s 100us/step - loss: 0.6348 - val_loss: 0.6366\n",
      "Epoch 49/50\n",
      "5000/5000 [==============================] - 1s 101us/step - loss: 0.6348 - val_loss: 0.6367\n",
      "Epoch 50/50\n",
      "5000/5000 [==============================] - 1s 102us/step - loss: 0.6349 - val_loss: 0.6367\n",
      "embedding created\n",
      "--- 5000 records ---\n",
      "--- 26.791825771331787 seconds ---\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 12)                36876     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 3072)              39936     \n",
      "=================================================================\n",
      "Total params: 77,019\n",
      "Trainable params: 77,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 12)                36876     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 36,975\n",
      "Trainable params: 36,975\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 1s 141us/step - loss: 0.6827 - val_loss: 0.6698\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 1s 81us/step - loss: 0.6652 - val_loss: 0.6637\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 1s 76us/step - loss: 0.6612 - val_loss: 0.6610\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 1s 80us/step - loss: 0.6587 - val_loss: 0.6586\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 1s 78us/step - loss: 0.6562 - val_loss: 0.6563\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 1s 75us/step - loss: 0.6536 - val_loss: 0.6537\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 1s 74us/step - loss: 0.6514 - val_loss: 0.6512\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 1s 77us/step - loss: 0.6486 - val_loss: 0.6486\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 1s 76us/step - loss: 0.6461 - val_loss: 0.6483\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 1s 76us/step - loss: 0.6440 - val_loss: 0.6442\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 1s 74us/step - loss: 0.6413 - val_loss: 0.6423\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 1s 76us/step - loss: 0.6392 - val_loss: 0.6420\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 1s 74us/step - loss: 0.6379 - val_loss: 0.6387\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 1s 74us/step - loss: 0.6366 - val_loss: 0.6399\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 1s 75us/step - loss: 0.6362 - val_loss: 0.6379\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 75us/step - loss: 0.6357 - val_loss: 0.6372\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 1s 78us/step - loss: 0.6353 - val_loss: 0.6368\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 1s 74us/step - loss: 0.6351 - val_loss: 0.6371\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 1s 76us/step - loss: 0.6350 - val_loss: 0.6367\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 1s 77us/step - loss: 0.6349 - val_loss: 0.6374\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 1s 75us/step - loss: 0.6353 - val_loss: 0.6373\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 1s 78us/step - loss: 0.6349 - val_loss: 0.6366\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 1s 80us/step - loss: 0.6348 - val_loss: 0.6365\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 1s 79us/step - loss: 0.6347 - val_loss: 0.6373\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 1s 77us/step - loss: 0.6350 - val_loss: 0.6365\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 1s 78us/step - loss: 0.6347 - val_loss: 0.6364\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 1s 78us/step - loss: 0.6347 - val_loss: 0.6364\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 1s 79us/step - loss: 0.6347 - val_loss: 0.6364\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 1s 78us/step - loss: 0.6346 - val_loss: 0.6364\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 1s 75us/step - loss: 0.6346 - val_loss: 0.6364\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 1s 84us/step - loss: 0.6347 - val_loss: 0.6366\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 1s 76us/step - loss: 0.6347 - val_loss: 0.6365\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 1s 71us/step - loss: 0.6347 - val_loss: 0.6365\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 1s 71us/step - loss: 0.6346 - val_loss: 0.6363\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 1s 77us/step - loss: 0.6346 - val_loss: 0.6369\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 1s 74us/step - loss: 0.6348 - val_loss: 0.6367\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 1s 78us/step - loss: 0.6346 - val_loss: 0.6365\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 1s 71us/step - loss: 0.6346 - val_loss: 0.6374\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 1s 71us/step - loss: 0.6348 - val_loss: 0.6370\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 1s 71us/step - loss: 0.6346 - val_loss: 0.6366\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 1s 71us/step - loss: 0.6346 - val_loss: 0.6365\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 1s 71us/step - loss: 0.6346 - val_loss: 0.6364\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 1s 71us/step - loss: 0.6345 - val_loss: 0.6366\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 1s 76us/step - loss: 0.6346 - val_loss: 0.6363\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 1s 71us/step - loss: 0.6345 - val_loss: 0.6363\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 1s 72us/step - loss: 0.6345 - val_loss: 0.6368\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 1s 71us/step - loss: 0.6346 - val_loss: 0.6364\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 1s 71us/step - loss: 0.6345 - val_loss: 0.6363\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 1s 71us/step - loss: 0.6345 - val_loss: 0.6363\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 1s 71us/step - loss: 0.6345 - val_loss: 0.6362\n",
      "embedding created\n",
      "--- 10000 records ---\n",
      "--- 39.01100158691406 seconds ---\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 12)                36876     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 3072)              39936     \n",
      "=================================================================\n",
      "Total params: 77,019\n",
      "Trainable params: 77,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 12)                36876     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 36,975\n",
      "Trainable params: 36,975\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "20000/20000 [==============================] - 2s 90us/step - loss: 0.6801 - val_loss: 0.6723\n",
      "Epoch 2/50\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.6647 - val_loss: 0.6594\n",
      "Epoch 3/50\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.6570 - val_loss: 0.6578\n",
      "Epoch 4/50\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.6528 - val_loss: 0.6509\n",
      "Epoch 5/50\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.6481 - val_loss: 0.6461\n",
      "Epoch 6/50\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.6445 - val_loss: 0.6682\n",
      "Epoch 7/50\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.6429 - val_loss: 0.6397\n",
      "Epoch 8/50\n",
      "20000/20000 [==============================] - 1s 58us/step - loss: 0.6374 - val_loss: 0.6382\n",
      "Epoch 9/50\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.6363 - val_loss: 0.6371\n",
      "Epoch 10/50\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.6357 - val_loss: 0.6363\n",
      "Epoch 11/50\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.6350 - val_loss: 0.6356\n",
      "Epoch 12/50\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.6343 - val_loss: 0.6353\n",
      "Epoch 13/50\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.6335 - val_loss: 0.6351\n",
      "Epoch 14/50\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.6323 - val_loss: 0.6327\n",
      "Epoch 15/50\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.6312 - val_loss: 0.6316\n",
      "Epoch 16/50\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.6302 - val_loss: 0.6305\n",
      "Epoch 17/50\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.6293 - val_loss: 0.6307\n",
      "Epoch 18/50\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.6287 - val_loss: 0.6301\n",
      "Epoch 19/50\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.6281 - val_loss: 0.6284\n",
      "Epoch 20/50\n",
      "20000/20000 [==============================] - 1s 58us/step - loss: 0.6272 - val_loss: 0.6288\n",
      "Epoch 21/50\n",
      "20000/20000 [==============================] - 1s 58us/step - loss: 0.6270 - val_loss: 0.6276\n",
      "Epoch 22/50\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.6270 - val_loss: 0.6276\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.6267 - val_loss: 0.6278\n",
      "Epoch 24/50\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.6266 - val_loss: 0.6275\n",
      "Epoch 25/50\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.6266 - val_loss: 0.6275\n",
      "Epoch 26/50\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.6264 - val_loss: 0.6275\n",
      "Epoch 27/50\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.6265 - val_loss: 0.6276\n",
      "Epoch 28/50\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.6264 - val_loss: 0.6272\n",
      "Epoch 29/50\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.6264 - val_loss: 0.6277\n",
      "Epoch 30/50\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.6264 - val_loss: 0.6282\n",
      "Epoch 31/50\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.6264 - val_loss: 0.6272\n",
      "Epoch 32/50\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.6263 - val_loss: 0.6274\n",
      "Epoch 33/50\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.6263 - val_loss: 0.6272\n",
      "Epoch 34/50\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.6263 - val_loss: 0.6305\n",
      "Epoch 35/50\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.6264 - val_loss: 0.6281\n",
      "Epoch 36/50\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.6263 - val_loss: 0.6271\n",
      "Epoch 37/50\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.6262 - val_loss: 0.6271\n",
      "Epoch 38/50\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.6262 - val_loss: 0.6274\n",
      "Epoch 39/50\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.6262 - val_loss: 0.6273\n",
      "Epoch 40/50\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.6262 - val_loss: 0.6271\n",
      "Epoch 41/50\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.6262 - val_loss: 0.6270\n",
      "Epoch 42/50\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.6261 - val_loss: 0.6270\n",
      "Epoch 43/50\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.6261 - val_loss: 0.6270\n",
      "Epoch 44/50\n",
      "20000/20000 [==============================] - 1s 64us/step - loss: 0.6261 - val_loss: 0.6271\n",
      "Epoch 45/50\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.6261 - val_loss: 0.6270\n",
      "Epoch 46/50\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.6261 - val_loss: 0.6272\n",
      "Epoch 47/50\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.6261 - val_loss: 0.6273\n",
      "Epoch 48/50\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.6261 - val_loss: 0.6276\n",
      "Epoch 49/50\n",
      "20000/20000 [==============================] - 1s 59us/step - loss: 0.6262 - val_loss: 0.6270\n",
      "Epoch 50/50\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.6261 - val_loss: 0.6269\n",
      "embedding created\n",
      "--- 20000 records ---\n",
      "--- 62.12968158721924 seconds ---\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 12)                36876     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 3072)              39936     \n",
      "=================================================================\n",
      "Total params: 77,019\n",
      "Trainable params: 77,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 12)                36876     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 36,975\n",
      "Trainable params: 36,975\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.6692 - val_loss: 0.6515\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 2s 56us/step - loss: 0.6478 - val_loss: 0.6463\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 2s 56us/step - loss: 0.6412 - val_loss: 0.6406\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 2s 54us/step - loss: 0.6367 - val_loss: 0.6368\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 2s 54us/step - loss: 0.6349 - val_loss: 0.6353\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 2s 55us/step - loss: 0.6335 - val_loss: 0.6334\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 2s 58us/step - loss: 0.6315 - val_loss: 0.6316\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 2s 56us/step - loss: 0.6296 - val_loss: 0.6297\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 2s 55us/step - loss: 0.6283 - val_loss: 0.6286\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6276 - val_loss: 0.6288\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6273 - val_loss: 0.6278\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6270 - val_loss: 0.6276\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 2s 56us/step - loss: 0.6268 - val_loss: 0.6274\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 2s 56us/step - loss: 0.6267 - val_loss: 0.6274\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6266 - val_loss: 0.6275\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6266 - val_loss: 0.6272\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6265 - val_loss: 0.6273\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6264 - val_loss: 0.6271\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 2s 59us/step - loss: 0.6264 - val_loss: 0.6271\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6264 - val_loss: 0.6275\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6264 - val_loss: 0.6274\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6264 - val_loss: 0.6270\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6263 - val_loss: 0.6270\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6264 - val_loss: 0.6276\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6264 - val_loss: 0.6270\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6263 - val_loss: 0.6270\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 2s 56us/step - loss: 0.6263 - val_loss: 0.6271\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 2s 56us/step - loss: 0.6263 - val_loss: 0.6271\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 2s 56us/step - loss: 0.6263 - val_loss: 0.6273\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6264 - val_loss: 0.6270\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 2s 55us/step - loss: 0.6264 - val_loss: 0.6271\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 2s 56us/step - loss: 0.6263 - val_loss: 0.6271\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 2s 53us/step - loss: 0.6263 - val_loss: 0.6270\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 2s 54us/step - loss: 0.6263 - val_loss: 0.6274\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 2s 52us/step - loss: 0.6263 - val_loss: 0.6271\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 2s 52us/step - loss: 0.6263 - val_loss: 0.6270\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6263 - val_loss: 0.6269\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 2s 53us/step - loss: 0.6262 - val_loss: 0.6270\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 2s 56us/step - loss: 0.6263 - val_loss: 0.6269\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 2s 52us/step - loss: 0.6263 - val_loss: 0.6272\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 2s 55us/step - loss: 0.6263 - val_loss: 0.6271\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 2s 58us/step - loss: 0.6262 - val_loss: 0.6269\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 2s 54us/step - loss: 0.6263 - val_loss: 0.6272\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 2s 54us/step - loss: 0.6262 - val_loss: 0.6271\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 2s 54us/step - loss: 0.6262 - val_loss: 0.6269\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6262 - val_loss: 0.6270\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 2s 52us/step - loss: 0.6262 - val_loss: 0.6269\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 2s 56us/step - loss: 0.6262 - val_loss: 0.6270\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 2s 57us/step - loss: 0.6262 - val_loss: 0.6269\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 2s 55us/step - loss: 0.6262 - val_loss: 0.6269\n",
      "embedding created\n",
      "--- 40000 records ---\n",
      "--- 113.2411675453186 seconds ---\n"
     ]
    }
   ],
   "source": [
    "def build_timer(x_train,x_test, size):\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    (x_train.shape, x_test.shape)\n",
    "    embedding = simple_autoencoder_CIFAR(x_train[:size], x_test)\n",
    "    print('embedding created')\n",
    "    print(\"--- %s records ---\" % size)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    process_time=(time.time() - start_time)\n",
    "    \n",
    "size=[100,1000,5000,10000, 20000,40000]\n",
    "process_time=[] \n",
    "alg=[] \n",
    "\n",
    "for n in size:\n",
    "    time =build_timer(x_train, x_test, n)\n",
    "    process_time.append(time)\n",
    "    alg.append('autoencoder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
