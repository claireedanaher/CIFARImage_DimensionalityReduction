{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "## This notebook serves as a starting point for the analysis which will be completed for each of the methods. It is important that the same data and dataformat feed into the analysis for consistency purposes\n",
    "\n",
    "- Import libraries\n",
    "- Update filepath directory\n",
    "- Activate import variables + functions\n",
    "- Import raw data\n",
    "- Convert data to a a 3072 dimension vector for each image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "#import download\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update filepath directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################################################################\n",
    "#Filepath for the CIFAR data\n",
    "# Set this before you start calling any of the functions below.\n",
    "data_path = \"C:\\\\WPI\\\\UnsupervisedLearning\\\\FinalProject\\\\cifar\\\\\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate import variables and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Various constants for the size of the images.\n",
    "# Use these constants in your own program.\n",
    "\n",
    "# Width and height of each image.\n",
    "img_size = 32\n",
    "\n",
    "# Number of channels in each image, 3 channels: Red, Green, Blue.\n",
    "num_channels = 3\n",
    "\n",
    "# Length of an image when flattened to a 1-dim array.\n",
    "img_size_flat = img_size * img_size * num_channels\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 10\n",
    "\n",
    "########################################################################\n",
    "# Various constants used to allocate arrays of the correct size.\n",
    "\n",
    "# Number of files for the training-set.\n",
    "_num_files_train = 5\n",
    "\n",
    "# Number of images for each batch-file in the training-set.\n",
    "_images_per_file = 10000\n",
    "\n",
    "# Total number of images in the training-set.\n",
    "# This is used to pre-allocate arrays for efficiency.\n",
    "_num_images_train = _num_files_train * _images_per_file\n",
    "\n",
    "########################################################################\n",
    "# Private functions for downloading, unpacking and loading data-files.\n",
    "\n",
    "\n",
    "def _get_file_path(filename=\"\"):\n",
    "    \"\"\"\n",
    "    Return the full path of a data-file for the data-set.\n",
    "    If filename==\"\" then return the directory of the files.\n",
    "    \"\"\"\n",
    "\n",
    "    return os.path.join(data_path,  filename)\n",
    "\n",
    "\n",
    "def _unpickle(filename):\n",
    "    \"\"\"\n",
    "    Unpickle the given file and return the data.\n",
    "    Note that the appropriate dir-name is prepended the filename.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create full path for the file.\n",
    "    file_path = _get_file_path(filename)\n",
    "\n",
    "    print(\"Loading data: \" + file_path)\n",
    "\n",
    "    with open(file_path, mode='rb') as file:\n",
    "        # In Python 3.X it is important to set the encoding,\n",
    "        # otherwise an exception is raised here.\n",
    "        data = pickle.load(file, encoding='bytes')\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def _convert_images(raw):\n",
    "    \"\"\"\n",
    "    Convert images from the CIFAR-10 format and\n",
    "    return a 4-dim array with shape: [image_number, height, width, channel]\n",
    "    where the pixels are floats between 0.0 and 1.0.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the raw images from the data-files to floating-points.\n",
    "    raw_float = np.array(raw, dtype=float) / 255.0\n",
    "\n",
    "    # Reshape the array to 4-dimensions.\n",
    "    images = raw_float.reshape([-1, num_channels, img_size, img_size])\n",
    "\n",
    "    # Reorder the indices of the array.\n",
    "    images = images.transpose([0, 2, 3, 1])\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def _load_data(filename):\n",
    "    \"\"\"\n",
    "    Load a pickled data-file from the CIFAR-10 data-set\n",
    "    and return the converted images (see above) and the class-number\n",
    "    for each image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the pickled data-file.\n",
    "    data = _unpickle(filename)\n",
    "\n",
    "    # Get the raw images.\n",
    "    raw_images = data[b'data']\n",
    "\n",
    "    # Get the class-numbers for each image. Convert to numpy-array.\n",
    "    cls = np.array(data[b'labels'])\n",
    "\n",
    "    # Convert the images.\n",
    "    images = _convert_images(raw_images)\n",
    "\n",
    "    return images, cls\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Public functions that you may call to download the data-set from\n",
    "# the internet and load the data into memory.\n",
    "\n",
    "\n",
    "def load_class_names():\n",
    "    \"\"\"\n",
    "    Load the names for the classes in the CIFAR-10 data-set.\n",
    "    Returns a list with the names. Example: names[3] is the name\n",
    "    associated with class-number 3.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the class-names from the pickled file.\n",
    "    raw = _unpickle(filename=\"batches.meta\")[b'label_names']\n",
    "\n",
    "    # Convert from binary strings.\n",
    "    names = [x.decode('utf-8') for x in raw]\n",
    "\n",
    "    return names\n",
    "\n",
    "\n",
    "def load_training_data():\n",
    "    \"\"\"\n",
    "    Load all the training-data for the CIFAR-10 data-set.\n",
    "    The data-set is split into 5 data-files which are merged here.\n",
    "    Returns the images, class-numbers and one-hot encoded class-labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Pre-allocate the arrays for the images and class-numbers for efficiency.\n",
    "    images = np.zeros(shape=[_num_images_train, img_size, img_size, num_channels], dtype=float)\n",
    "    cls = np.zeros(shape=[_num_images_train], dtype=int)\n",
    "\n",
    "    # Begin-index for the current batch.\n",
    "    begin = 0\n",
    "\n",
    "    # For each data-file.\n",
    "    for i in range(_num_files_train):\n",
    "        # Load the images and class-numbers from the data-file.\n",
    "        images_batch, cls_batch = _load_data(filename=\"data_batch_\" + str(i + 1))\n",
    "\n",
    "        # Number of images in this batch.\n",
    "        num_images = len(images_batch)\n",
    "\n",
    "        # End-index for the current batch.\n",
    "        end = begin + num_images\n",
    "\n",
    "        # Store the images into the array.\n",
    "        images[begin:end, :] = images_batch\n",
    "\n",
    "        # Store the class-numbers into the array.\n",
    "        cls[begin:end] = cls_batch\n",
    "\n",
    "        # The begin-index for the next batch is the current end-index.\n",
    "        begin = end\n",
    "\n",
    "    return images, cls\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    \"\"\"\n",
    "    Load all the test-data for the CIFAR-10 data-set.\n",
    "    Returns the images, class-numbers and one-hot encoded class-labels.\n",
    "    \"\"\"\n",
    "\n",
    "    images, cls = _load_data(filename=\"test_batch\")\n",
    "\n",
    "    return images, cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: C:\\WPI\\UnsupervisedLearning\\FinalProject\\cifar\\data_batch_1\n",
      "Loading data: C:\\WPI\\UnsupervisedLearning\\FinalProject\\cifar\\data_batch_2\n",
      "Loading data: C:\\WPI\\UnsupervisedLearning\\FinalProject\\cifar\\data_batch_3\n",
      "Loading data: C:\\WPI\\UnsupervisedLearning\\FinalProject\\cifar\\data_batch_4\n",
      "Loading data: C:\\WPI\\UnsupervisedLearning\\FinalProject\\cifar\\data_batch_5\n",
      "[[[[0.60392157 0.69411765 0.73333333]\n",
      "   [0.49411765 0.5372549  0.53333333]\n",
      "   [0.41176471 0.40784314 0.37254902]\n",
      "   ...\n",
      "   [0.35686275 0.37254902 0.27843137]\n",
      "   [0.34117647 0.35294118 0.27843137]\n",
      "   [0.30980392 0.31764706 0.2745098 ]]\n",
      "\n",
      "  [[0.54901961 0.62745098 0.6627451 ]\n",
      "   [0.56862745 0.6        0.60392157]\n",
      "   [0.49019608 0.49019608 0.4627451 ]\n",
      "   ...\n",
      "   [0.37647059 0.38823529 0.30588235]\n",
      "   [0.30196078 0.31372549 0.24313725]\n",
      "   [0.27843137 0.28627451 0.23921569]]\n",
      "\n",
      "  [[0.54901961 0.60784314 0.64313725]\n",
      "   [0.54509804 0.57254902 0.58431373]\n",
      "   [0.45098039 0.45098039 0.43921569]\n",
      "   ...\n",
      "   [0.30980392 0.32156863 0.25098039]\n",
      "   [0.26666667 0.2745098  0.21568627]\n",
      "   [0.2627451  0.27058824 0.21568627]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.68627451 0.65490196 0.65098039]\n",
      "   [0.61176471 0.60392157 0.62745098]\n",
      "   [0.60392157 0.62745098 0.66666667]\n",
      "   ...\n",
      "   [0.16470588 0.13333333 0.14117647]\n",
      "   [0.23921569 0.20784314 0.22352941]\n",
      "   [0.36470588 0.3254902  0.35686275]]\n",
      "\n",
      "  [[0.64705882 0.60392157 0.50196078]\n",
      "   [0.61176471 0.59607843 0.50980392]\n",
      "   [0.62352941 0.63137255 0.55686275]\n",
      "   ...\n",
      "   [0.40392157 0.36470588 0.37647059]\n",
      "   [0.48235294 0.44705882 0.47058824]\n",
      "   [0.51372549 0.4745098  0.51372549]]\n",
      "\n",
      "  [[0.63921569 0.58039216 0.47058824]\n",
      "   [0.61960784 0.58039216 0.47843137]\n",
      "   [0.63921569 0.61176471 0.52156863]\n",
      "   ...\n",
      "   [0.56078431 0.52156863 0.54509804]\n",
      "   [0.56078431 0.5254902  0.55686275]\n",
      "   [0.56078431 0.52156863 0.56470588]]]]\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "#Import image data using import functions     \n",
    "raw_images, cls=load_training_data()\n",
    "\n",
    "\n",
    "#Print variable to confirm import correctly\n",
    "print(raw_images[1:2]) \n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify correct import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153600000\n",
      "153600000\n"
     ]
    }
   ],
   "source": [
    "#Check data type--> should by np array\n",
    "type(raw_images)\n",
    "#Check number of images --> should be 50000\n",
    "len(raw_images)\n",
    "\n",
    "#Check data dimensions\n",
    "#Correct dimensions:\n",
    "print(3072*50000)\n",
    "#Imported Dimensions\n",
    "print(raw_images.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert original array to correct 3072 dim array per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images_flat=raw_images.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_color = images_flat.reshape(-1, img_size_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60392157 0.69411765 0.73333333 ... 0.56078431 0.52156863 0.56470588]\n"
     ]
    }
   ],
   "source": [
    "print(images_color[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run PCA on color image vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=3072, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN PCA on images\n",
    "pca = PCA(n_components=img_size_flat)\n",
    "pca.fit(images_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Explained Variance\n",
      "[2.90766299e-01 1.12531437e-01 6.69441396e-02 ... 8.64946450e-09\n",
      " 8.45232138e-09 8.33587056e-09]\n",
      "\n",
      "Singular Values\n",
      "[1.66376404e+03 1.03503880e+03 7.98318108e+02 ... 2.86955338e-01\n",
      " 2.83666271e-01 2.81705405e-01]\n",
      "\n",
      "Cumulative Explained Variance\n",
      "[29.08 40.33 47.02 ... 98.77 98.77 98.77]\n"
     ]
    }
   ],
   "source": [
    "#PRINT Explained Variance Ratio\n",
    "print('\\n Explained Variance')\n",
    "print(pca.explained_variance_ratio_) \n",
    "print('\\nSingular Values')\n",
    "print(pca.singular_values_) \n",
    "print('\\nCumulative Explained Variance')\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "print(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fb4e1193c8>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(var1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
